{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0124a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_recall_curve,\n",
    "                             f1_score, classification_report, confusion_matrix, \n",
    "                             roc_auc_score, roc_curve, accuracy_score)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "889e9bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"../data/results/data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdd23988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CustomerID       1000 non-null   int64  \n",
      " 1   Age              1000 non-null   int64  \n",
      " 2   Gender           1000 non-null   object \n",
      " 3   MaritalStatus    1000 non-null   object \n",
      " 4   IncomeLevel      1000 non-null   object \n",
      " 5   TotalSpent       1000 non-null   float64\n",
      " 6   NumTransactions  1000 non-null   int64  \n",
      " 7   NumInteractions  1000 non-null   float64\n",
      " 8   UnresolvedCount  1000 non-null   float64\n",
      " 9   LastLoginDate    1000 non-null   object \n",
      " 10  LoginFrequency   1000 non-null   int64  \n",
      " 11  ServiceUsage     1000 non-null   object \n",
      " 12  ChurnStatus      1000 non-null   int64  \n",
      " 13  Churn            1000 non-null   object \n",
      " 14  AgeGroup         1000 non-null   object \n",
      "dtypes: float64(3), int64(5), object(7)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f862b",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oridnal encode Income Level\n",
    "\n",
    "train['IncomeLevelEncoded'] = train['IncomeLevel'].map({\n",
    "    'Low': 0,\n",
    "    'Medium': 2,\n",
    "    'High': 3\n",
    "})\n",
    "\n",
    "# Drop columns that aren't helpful or are now redundant\n",
    "drop_cols = [\n",
    "    'CustomerID', 'LastLoginDate', 'Churn', 'AgeGroup', 'IncomeLevel'  # drop original as it's now encoded\n",
    "]\n",
    "train.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = train.drop(columns='ChurnStatus')\n",
    "y = train['ChurnStatus']\n",
    "\n",
    "# One-hot encode other categorical variables (leave ordinal ones)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Scale numeric values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert target to categorical\n",
    "num_classes = len(y.unique())\n",
    "\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Build the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880aa661",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "Algorithm: Random Forest\n",
    "\n",
    "Hyper-parameter tuning: Grid Search\n",
    "\n",
    "Optimization: Precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected threshold: 0.45 (Recall ≥ 0.80, F1 = 0.789)\n",
      "{\n",
      "  \"0\": {\n",
      "    \"precision\": 0.9182692307692307,\n",
      "    \"recall\": 0.9009433962264151,\n",
      "    \"f1-score\": 0.9095238095238095,\n",
      "    \"support\": 212.0\n",
      "  },\n",
      "  \"1\": {\n",
      "    \"precision\": 0.7717391304347826,\n",
      "    \"recall\": 0.8068181818181818,\n",
      "    \"f1-score\": 0.7888888888888889,\n",
      "    \"support\": 88.0\n",
      "  },\n",
      "  \"accuracy\": 0.8733333333333333,\n",
      "  \"macro avg\": {\n",
      "    \"precision\": 0.8450041806020067,\n",
      "    \"recall\": 0.8538807890222984,\n",
      "    \"f1-score\": 0.8492063492063492,\n",
      "    \"support\": 300.0\n",
      "  },\n",
      "  \"weighted avg\": {\n",
      "    \"precision\": 0.8752870680044592,\n",
      "    \"recall\": 0.8733333333333333,\n",
      "    \"f1-score\": 0.8741375661375662,\n",
      "    \"support\": 300.0\n",
      "  }\n",
      "}\n",
      "ROC AUC: 0.905\n",
      "Accuracy: 0.873\n",
      "Confusion Matrix:\n",
      "[[191  21]\n",
      " [ 17  71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, classification_report, confusion_matrix,\n",
    "    roc_auc_score, accuracy_score\n",
    ")\n",
    "\n",
    "# 1. Data\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=20, weights=[0.7, 0.3], random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Pipeline with SMOTE + Tomek\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTETomek(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# 3. GridSearch with better scoring (area under PR curve = more recall-robust)\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [100, 200],\n",
    "    'rf__max_depth': [5, 10],\n",
    "    'rf__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='average_precision',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 4. Extract tuned model + reapply resampling manually for calibration\n",
    "best_pipeline = grid.best_estimator_\n",
    "rf_best = best_pipeline.named_steps['rf']\n",
    "smote_X_train, smote_y_train = best_pipeline.named_steps['smote'].fit_resample(X_train, y_train)\n",
    "\n",
    "# 5. Calibrate\n",
    "calibrated_rf = CalibratedClassifierCV(estimator=rf_best, method='sigmoid', cv=3)\n",
    "calibrated_rf.fit(smote_X_train, smote_y_train)\n",
    "\n",
    "# 6. Predict calibrated probabilities\n",
    "y_proba = calibrated_rf.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# 7. Threshold for Recall ≥ 80% + Best F1\n",
    "best_thresh = 0.5\n",
    "best_f1 = 0\n",
    "for p, r, t in zip(precision, recall, thresholds):\n",
    "    if r >= 0.80:\n",
    "        f1 = 2 * p * r / (p + r + 1e-10)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = t\n",
    "\n",
    "print(f\"Selected threshold: {best_thresh:.2f} (Recall ≥ 0.80, F1 = {best_f1:.3f})\")\n",
    "\n",
    "# 8. Final Prediction\n",
    "y_pred = (y_proba >= best_thresh).astype(int)\n",
    "\n",
    "# 9. Evaluation\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(json.dumps(report, indent=2))\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "# 10. Save\n",
    "metrics_output = {\n",
    "    \"best_params\": grid.best_params_,\n",
    "    \"chosen_threshold\": float(best_thresh),\n",
    "    \"target_recall_f1\": best_f1,\n",
    "    \"roc_auc\": roc_auc,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"confusion_matrix\": conf_matrix.tolist(),\n",
    "    \"classification_report\": report\n",
    "}\n",
    "\n",
    "with open(\"model_metrics_balanced_smote_tomek.json\", \"w\") as f:\n",
    "    json.dump(metrics_output, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba2e12",
   "metadata": {},
   "source": [
    "## Model Evaluation: Precisin, Recall, F1-score, AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36fbb0da",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [300, 200]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- 5. Evaluate the model ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_opt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Confusion matrix\u001b[39;00m\n\u001b[32m      5\u001b[39m conf_mat = confusion_matrix(y_test, y_pred_opt)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:2671\u001b[39m, in \u001b[36mclassification_report\u001b[39m\u001b[34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[32m   2564\u001b[39m \n\u001b[32m   2565\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2667\u001b[39m \u001b[33;03m<BLANKLINE>\u001b[39;00m\n\u001b[32m   2668\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2670\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m-> \u001b[39m\u001b[32m2671\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2674\u001b[39m     labels = unique_labels(y_true, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:98\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m     73\u001b[39m \u001b[33;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m xp, _ = get_namespace(y_true, y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m type_true = type_of_target(y_true, input_name=\u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [300, 200]"
     ]
    }
   ],
   "source": [
    "# --- 5. Evaluate the model ---\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_opt))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_opt)\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091779a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
